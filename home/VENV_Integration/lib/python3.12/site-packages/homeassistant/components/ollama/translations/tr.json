{
    "config": {
        "error": {
            "cannot_connect": "Ba\u011flanma hatas\u0131",
            "download_failed": "Model indirme i\u015flemi ba\u015far\u0131s\u0131z oldu",
            "unknown": "Beklenmeyen hata"
        },
        "progress": {
            "download": "Model indirilirken l\u00fctfen bekleyiniz, bu i\u015flem \u00e7ok uzun s\u00fcrebilir. Daha fazla ayr\u0131nt\u0131 i\u00e7in Ollama sunucu g\u00fcnl\u00fcklerinizi kontrol edin."
        },
        "step": {
            "download": {
                "title": "Model indiriliyor"
            },
            "user": {
                "data": {
                    "model": "Model",
                    "url": "URL"
                }
            }
        }
    },
    "options": {
        "step": {
            "init": {
                "data": {
                    "keep_alive": "Canl\u0131 tutun",
                    "llm_hass_api": "Home Assistant'\u0131 kontrol et",
                    "max_history": "Maksimum ge\u00e7mi\u015f iletisi",
                    "num_ctx": "Ba\u011flam penceresi boyutu",
                    "prompt": "Talimatlar"
                },
                "data_description": {
                    "keep_alive": "Ollama'n\u0131n modeli haf\u0131zada tutmas\u0131 i\u00e7in saniye cinsinden s\u00fcre. -1 = belirsiz, 0 = asla.",
                    "num_ctx": "Modelin i\u015fleyebilece\u011fi maksimum metin belirteci say\u0131s\u0131. Ollama RAM'ini azaltmak i\u00e7in d\u00fc\u015f\u00fcr\u00fcn veya \u00e7ok say\u0131da a\u00e7\u0131k varl\u0131k i\u00e7in art\u0131r\u0131n.",
                    "prompt": "LLM'nin nas\u0131l yan\u0131t vermesi gerekti\u011fini \u00f6\u011fretin. Bu bir \u015fablon olabilir."
                }
            }
        }
    }
}